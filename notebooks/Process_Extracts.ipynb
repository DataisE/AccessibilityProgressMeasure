{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573e38cf-3e4d-46af-b431-4f079d7a8152",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-11-09T17:39:50.7679477Z",
       "execution_start_time": "2024-11-09T17:39:47.478827Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "bcf3e238-89f7-4240-bc07-dc9797a5271c",
       "queued_time": "2024-11-09T17:38:34.0579566Z",
       "session_id": "b590fb83-e2dd-4388-8283-07f01496f435",
       "session_start_time": "2024-11-09T17:38:34.5156032Z",
       "spark_pool": null,
       "state": "finished",
       "statement_id": 5,
       "statement_ids": [
        5
       ]
      },
      "text/plain": [
       "StatementMeta(, b590fb83-e2dd-4388-8283-07f01496f435, 5, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##### Working Code ####\n",
    "import notebookutils, csv\n",
    "import os, json, time, pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "\n",
    "areas = [\"Employment\"]\n",
    "# , \"Information and Communication Technology\"]\n",
    "#        \"Communications other than ICT\",\n",
    "#         \"Design and Delivery of Programs and Services\", \"Procurement of goods, services and facilities\",\n",
    "#        \"Transportation\", \"Built Environment\"]\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"xxxxxxxxxxxxxxxxxx\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"xxxxxxxxxxxxxxxxxxxxxxx\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26be01d0-504d-4e29-9cd6-75b45b597381",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-11-09T17:39:51.7035631Z",
       "execution_start_time": "2024-11-09T17:39:51.373704Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "41eb54a6-4056-4248-b5f4-7a320818e222",
       "queued_time": "2024-11-09T17:38:34.0597803Z",
       "session_id": "b590fb83-e2dd-4388-8283-07f01496f435",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 6,
       "statement_ids": [
        6
       ]
      },
      "text/plain": [
       "StatementMeta(, b590fb83-e2dd-4388-8283-07f01496f435, 6, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Working Code\n",
    "\n",
    "def json_extract(obj, key):\n",
    "    \"\"\"Recursively fetch values from nested JSON.\"\"\"\n",
    "    arr = []\n",
    "\n",
    "    def extract(obj, arr, key):\n",
    "        \"\"\"Recursively search for values of key in JSON tree.\"\"\"\n",
    "        if isinstance(obj, dict):\n",
    "            for k, v in obj.items():\n",
    "                if isinstance(v, (dict, list)):\n",
    "                    extract(v, arr, key)\n",
    "                elif k == key:\n",
    "                    arr.append(v)\n",
    "        elif isinstance(obj, list):\n",
    "            for item in obj:\n",
    "                extract(item, arr, key)\n",
    "        return arr\n",
    "\n",
    "    values = extract(obj, arr, key)\n",
    "    return values[0]\n",
    "\n",
    "\n",
    "def extract_accessibility_area_plan_progress(sector, org, doc_type, processed_file_path, file_path):\n",
    "    res = []\n",
    "    \"\"\"sec = []\n",
    "    orgn = []\n",
    "    d_t = []\n",
    "    ar = []\"\"\"\n",
    "\n",
    "    embeddings = AzureOpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "    client = AzureOpenAI()\n",
    "\n",
    "    loader = PyPDFLoader(file_path)\n",
    "    pages = loader.load_and_split()\n",
    "\n",
    "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "    texts = text_splitter.split_documents(pages)\n",
    "    faiss_index = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "    for area in areas:\n",
    "        query = f\"What are the planned actions to address barriers for the ' {area} Area'?\"\n",
    "        docs = faiss_index.similarity_search(query, k=5)\n",
    "\n",
    "        text = \"\"\n",
    "        for doc in docs:\n",
    "            text += doc.page_content\n",
    "\n",
    "        if doc_type == \"Plans\":\n",
    "            prompt = f\"Extract the planned tasks and activities documented under the {area} section in the attached text :\\n{text}\"\n",
    "        else:\n",
    "            prompt = f\"Extract the progress being made to implement the planned tasks and activities documented under the {area} section in the attached text :\\n{text}\"\n",
    "\n",
    "\n",
    "        MESSAGES = [\n",
    "            {\"role\": \"system\", \"content\": \"You are an accessibility compliance analyst.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "\n",
    "        time.sleep(60)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-turbo-2024-04-09\",\n",
    "            temperature=0.0,\n",
    "            top_p=0,\n",
    "            messages=MESSAGES\n",
    "        )\n",
    "\n",
    "        parsed_data = json.loads(response.json())\n",
    "        content = json_extract(parsed_data, \"content\")\n",
    "        # sector, org, doc_type, area, content  \n",
    "        # sec.append(sector)\n",
    "        # orgn.append(org)\n",
    "        # d_t.append(doc_type)\n",
    "        # ar.append(area)\n",
    "        res.append(content)\n",
    "        time.sleep(60)\n",
    "    create_or_append_json(sector, org, doc_type, area, res, processed_file_path)\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def create_or_append_json(sector, org, doc_type, area, res, processed_file_path):\n",
    "\n",
    "    for area_desc in res:\n",
    "        new_data = {\n",
    "            \"sector\": sector,\n",
    "            \"org\": org,\n",
    "            \"doc_type\": doc_type,\n",
    "            \"area\": area,\n",
    "            \"area_desc\": area_desc\n",
    "            }\n",
    "\n",
    "        # Check if file exists and has content\n",
    "        if notebookutils.fs.exists(\"file:\" + processed_file_path):\n",
    "            # Read existing data\n",
    "            with open(processed_file_path, 'r') as file:\n",
    "                try:\n",
    "                    data = json.load(file)\n",
    "                    \n",
    "                    # Handle different data structures\n",
    "                    if isinstance(data, list):\n",
    "                        data.append(new_data)\n",
    "                    elif isinstance(data, dict):\n",
    "                        if 'items' not in data:\n",
    "                            data['items'] = []\n",
    "                        data['items'].append(new_data)\n",
    "                    else:\n",
    "                        # If neither list nor dict, wrap existing data and new data in a list\n",
    "                        data = [data, new_data]\n",
    "                        \n",
    "                except json.JSONDecodeError:\n",
    "                    print(\"Error: File contains invalid JSON. Creating new file...\")\n",
    "                    data = {'items': [new_data]}\n",
    "        else:\n",
    "            # Create new file with initial data\n",
    "            data = {'items': [new_data]}\n",
    "        \n",
    "        # Write data back to file\n",
    "        with open(processed_file_path, 'w') as file:\n",
    "            json.dump(data, file, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f45e8e7-af77-4f8e-8315-166f2076a1af",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-11-09T20:31:16.300859Z",
       "execution_start_time": "2024-11-09T20:31:15.9619118Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "9d9f87e4-575c-4405-882c-6cae60246f71",
       "queued_time": "2024-11-09T20:31:15.2487403Z",
       "session_id": "a8e26522-4105-4fcd-9947-ca8f4d998957",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 7,
       "statement_ids": [
        7
       ]
      },
      "text/plain": [
       "StatementMeta(, a8e26522-4105-4fcd-9947-ca8f4d998957, 7, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc_type = \"Plans\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7981aff-f63b-47d5-aff3-c3c36ca0109b",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-11-09T17:46:33.7102704Z",
       "execution_start_time": "2024-11-09T17:39:52.3625954Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "30f8876f-5b3a-4fa5-b56f-8856949b55b8",
       "queued_time": "2024-11-09T17:38:34.060449Z",
       "session_id": "b590fb83-e2dd-4388-8283-07f01496f435",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 7,
       "statement_ids": [
        7
       ]
      },
      "text/plain": [
       "StatementMeta(, b590fb83-e2dd-4388-8283-07f01496f435, 7, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plans = notebookutils.fs.ls('file:/lakehouse/default/Files/Bronze/Plans')\n",
    "progressreports = notebookutils.fs.ls('file:/lakehouse/default/Files/Bronze/ProgressReports')\n",
    "\n",
    "if doc_type == \"Plans\":\n",
    "    files = plans\n",
    "    processed_file_path = \"/lakehouse/default/Files/Silver/plans.json\"\n",
    "else:\n",
    "    files = progressreports\n",
    "    processed_file_path = \"/lakehouse/default/Files/Silver/progressreports.json\"\n",
    "\n",
    "\n",
    "## Extract details from each accessibility sections\n",
    "for file in files:\n",
    "    file_split = file.name.rsplit(\"-\")\n",
    "    sector = file_split[1]\n",
    "    org = file_split[2]\n",
    "    response = extract_accessibility_area_plan_progress(sector, org, doc_type, processed_file_path, file.path.replace('file:', ''))\n",
    "\n",
    "\n",
    "\n",
    "move_processed_files(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f42122c-9094-4a2e-8cfc-4feb0924ccc2",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#### move files to processed folder\n",
    "def move_processed_files (file_list):\n",
    "    destination_path = \"file:/lakehouse/default/Files/Bronze/ProcessedFiles\"\n",
    "\n",
    "    for file in file_list:\n",
    "        # Move files from source to destination\n",
    "        notebookutils.fs.mv(file.path, destination_path)\n",
    "\n",
    "    # Verify if files were moved successfully\n",
    "    print(f\"Files moved from {source_path} to {destination_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3bb96-fd5d-41fc-afef-f6573cf08e06",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2024-11-09T17:46:34.7698729Z",
       "execution_start_time": "2024-11-09T17:46:34.449267Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "f6c7ffac-5393-4208-a92a-035352a08b92",
       "queued_time": "2024-11-09T17:38:34.0615956Z",
       "session_id": "b590fb83-e2dd-4388-8283-07f01496f435",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 8,
       "statement_ids": [
        8
       ]
      },
      "text/plain": [
       "StatementMeta(, b590fb83-e2dd-4388-8283-07f01496f435, 8, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sector = \"Telecom\"\n",
    "# org = \"telecom2\"\n",
    "# area = \"Employment\"\n",
    "# doc_type = \"Progress Report\"\n",
    "# res = [\"a\",\"b\",\"c\"]\n",
    "# res =  [\"The planned tasks and activities documented under the Employment section in the text are as follows:\\n\\n1. **Regular Reviews of Accommodations Program**: Continue to conduct regular reviews of the accommodations program, in consultation with employees with disabilities, to identify opportunities to improve support. This task is ongoing.\\n\\n2. **Creation of an Employee Accessibility Hub**: Develop and continuously update an employee Accessibility Hub that will serve as a centralized source of accessibility-related resources. This includes training, policies, key contacts, and guidance on how to request accommodations and provide feedback. This task is categorized as short term.\\n\\n3. **Proactive Communication about Accessibility Policies and Offerings**: Enhance proactive communication regarding accessibility policies and offerings. This task is planned for the medium term.\\n\\n4. **Update Accessibility Training for Managers**: Update the accessibility training provided to managers to promote transparent conversations with employees about their disabilities, the accommodations they need, and how to better support them in the workplace. This task is also planned for the medium term.\\n\\n5. **Formalize Mentorship Programs**: Formalize mentorship programs to support employees with disabilities in their career development. This task is planned for the long term.\", \"'The planned tasks and activities documented under the Employment section in the text are as follows:\\n\\n1. **Regular Reviews of Accommodations Program**: Continue to conduct regular reviews of the accommodations program, in consultation with employees with disabilities, to identify opportunities to improve support. This task is ongoing.\\n\\n2. **Creation of an Employee Accessibility Hub**: Develop and continuously update an employee Accessibility Hub that will serve as a centralized source of accessibility-related resources. This includes training, policies, key contacts, and guidance on how to request accommodations and provide feedback. This task is categorized as short term.\\n\\n3. **Proactive Communication about Accessibility Policies and Offerings**: Enhance proactive communication regarding accessibility policies and offerings. This task is planned for the medium term.\\n\\n4. **Update Accessibility Training for Managers**: Update the accessibility training provided to managers to promote transparent conversations with employees about their disabilities, the accommodations they need, and how to better support them in the workplace. This task is also planned for the medium term.\\n\\n5. **Formalize Mentorship Programs**: Formalize mentorship programs to support employees with disabilities in their career development. This task is planned for the long term.\",\"'The planned tasks and activities documented under the Employment section in the text are as follows:\\n\\n1. **Regular Reviews of Accommodations Program**: Continue to conduct regular reviews of the accommodations program, in consultation with employees with disabilities, to identify opportunities to improve support. This task is ongoing.\\n\\n2. **Creation of an Employee Accessibility Hub**: Develop and continuously update an employee Accessibility Hub that will serve as a centralized source of accessibility-related resources. This includes training, policies, key contacts, and guidance on how to request accommodations and provide feedback. This task is categorized as short term.\\n\\n3. **Proactive Communication about Accessibility Policies and Offerings**: Enhance proactive communication regarding accessibility policies and offerings. This task is planned for the medium term.\\n\\n4. **Update Accessibility Training for Managers**: Update the accessibility training provided to managers to promote transparent conversations with employees about their disabilities, the accommodations they need, and how to better support them in the workplace. This task is also planned for the medium term.\\n\\n5. **Formalize Mentorship Programs**: Formalize mentorship programs to support employees with disabilities in their career development. This task is planned for the long term.\",\"'The planned tasks and activities documented under the Employment section in the text are as follows:\\n\\n1. **Regular Reviews of Accommodations Program**: Continue to conduct regular reviews of the accommodations program, in consultation with employees with disabilities, to identify opportunities to improve support. This task is ongoing.\\n\\n2. **Creation of an Employee Accessibility Hub**: Develop and continuously update an employee Accessibility Hub that will serve as a centralized source of accessibility-related resources. This includes training, policies, key contacts, and guidance on how to request accommodations and provide feedback. This task is categorized as short term.\\n\\n3. **Proactive Communication about Accessibility Policies and Offerings**: Enhance proactive communication regarding accessibility policies and offerings. This task is planned for the medium term.\\n\\n4. **Update Accessibility Training for Managers**: Update the accessibility training provided to managers to promote transparent conversations with employees about their disabilities, the accommodations they need, and how to better support them in the workplace. This task is also planned for the medium term.\\n\\n5. **Formalize Mentorship Programs**: Formalize mentorship programs to support employees with disabilities in their career development. This task is planned for the long term.\"]\n",
    "# processed_file_path = \"/lakehouse/default/Files/Silver/processed.json\"\n",
    "# create_or_append_json(sector, org, doc_type, area, res, processed_file_path)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {
    "environmentId": "9404e2c8-317c-413e-8ed6-32fd3d16c20e",
    "workspaceId": "d63a3ade-af13-485a-8f48-9d233c335d35"
   },
   "lakehouse": {
    "default_lakehouse": "c4fcfdd3-d245-4b89-ae87-03b2041bed02",
    "default_lakehouse_name": "Accessibility_LH",
    "default_lakehouse_workspace_id": "d63a3ade-af13-485a-8f48-9d233c335d35"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {},
   "version": "0.1"
  },
  "widgets": {}
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
